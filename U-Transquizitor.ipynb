{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ae7b4f-50f4-4e2a-a0f4-ffc6c081241d",
   "metadata": {},
   "source": [
    "# Youtube Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f5f790-d4bf-465e-9986-443f505971d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for summarization\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "from transformers import pipeline\n",
    "\n",
    "def extract_video_id(url):\n",
    "    # Extract video ID from the YouTube URL\n",
    "    match = re.search(r\"(?:v=|\\/)([a-zA-Z0-9_-]{11}).*\", url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_auto_captions(youtube_url):\n",
    "    video_id = extract_video_id(youtube_url)\n",
    "    transcript_text = \"\"\n",
    "    \n",
    "    if video_id:\n",
    "        try:\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            transcript_text = \" \".join([entry['text'] for entry in transcript])\n",
    "            transcript_length = len(transcript_text)\n",
    "            return transcript_text, transcript_length\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching auto-generated captions: {e}\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(\"Invalid YouTube URL. Please provide a valid video URL.\")\n",
    "        return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d055b-394b-4829-94e6-2740c00ffbcf",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bffe1a-6805-4eb0-a545-0daecaeba4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\8th sem\\NLP\\NLP\\env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline('summarization',max_length=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970c9516-f0e2-424b-8bc8-6fdb4dd67327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(youtube_url, summarizer, max_length=56):\n",
    "    # Call get_auto_captions to retrieve transcript text and length\n",
    "    transcript, transcript_length = get_auto_captions(youtube_url)\n",
    "    \n",
    "    if transcript:\n",
    "        num_iters = int(transcript_length / 1000)\n",
    "        summarized_text = []\n",
    "\n",
    "        for i in range(0, num_iters + 1):\n",
    "            start = i * 1000\n",
    "            end = (i + 1) * 1000\n",
    "            input_text = transcript[start:end]\n",
    "            #print(\"Input text:\\n\", input_text)\n",
    "\n",
    "            out = summarizer(input_text, max_length=max_length)\n",
    "            out = out[0]\n",
    "            out = out['summary_text']\n",
    "\n",
    "            #print(\"Summarized text:\\n\", out)\n",
    "            summarized_text.append(out)\n",
    "        \n",
    "        return str(summarized_text)\n",
    "    else:\n",
    "        print(\"Failed to retrieve transcript from the YouTube video.\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a5c141-dd53-479d-8086-ee4d89143b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#youtube_url = \"https://www.youtube.com/watch?v=A4OmtyaBHFE\"\n",
    "\n",
    "# Call summarize_video function\n",
    "#summarized_text = summarize(youtube_url, summarizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb9e40-3f37-4984-a65c-01dc98506631",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050674d-06d1-4b83-8733-3eef7aa830bd",
   "metadata": {},
   "source": [
    "## 1.Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b086e4-26cf-48a9-83b4-8cb675ac0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "189e4690-6b9c-4625-aed8-f084ef1076ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88866900-a047-4ff3-b440-84fc48f23849",
   "metadata": {},
   "source": [
    "## 2.Load the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a01b0990-936d-4c76-9ea6-10e549994045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d85447c65a47a3965819bb5dab530b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f816447-875a-4bb4-a3be-631733d0fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acd954be-799d-4fa7-8301-404ca203f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc773e5-a072-4d37-a63c-81f0d2ff0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline('translation', model=model, tokenizer=tokenizer, src_lang=\"eng_Latn\", tgt_lang='tam_Taml', max_length = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929af9b-89b2-4b01-927a-1fc30855291a",
   "metadata": {},
   "source": [
    "# Generating MCQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdd22ee1-766e-4def-8492-b2412fd71530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2daf73c1-fdec-4f5d-b743-050890199b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0fbad14-2907-4079-b79f-6b8de11d54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mcqs(text, num_questions=5):\n",
    "    # text = clean_text(text)\n",
    "    if text is None:\n",
    "        return []\n",
    "\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract sentences from the text\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "\n",
    "    # Ensure that the number of questions does not exceed the number of sentences\n",
    "    num_questions = min(num_questions, len(sentences))\n",
    "\n",
    "    # Randomly select sentences to form questions\n",
    "    selected_sentences = random.sample(sentences, num_questions)\n",
    "\n",
    "    # Initialize list to store generated MCQs\n",
    "    mcqs = []\n",
    "\n",
    "    # Generate MCQs for each selected sentence\n",
    "    for sentence in selected_sentences:\n",
    "        # Process the sentence with spaCy\n",
    "        sent_doc = nlp(sentence)\n",
    "\n",
    "        # Extract entities (nouns) from the sentence\n",
    "        nouns = [token.text for token in sent_doc if token.pos_ == \"NOUN\"]\n",
    "\n",
    "        # Ensure there are enough nouns to generate MCQs\n",
    "        if len(nouns) < 2:\n",
    "            continue\n",
    "\n",
    "        # Count the occurrence of each noun\n",
    "        noun_counts = Counter(nouns)\n",
    "\n",
    "        # Select the most common noun as the subject of the question\n",
    "        if noun_counts:\n",
    "            subject = noun_counts.most_common(1)[0][0]\n",
    "\n",
    "            # Generate the question stem\n",
    "            question_stem = sentence.replace(subject, \"______\")\n",
    "\n",
    "            # Generate answer choices\n",
    "            answer_choices = [subject]\n",
    "\n",
    "            # Add some random words from the text as distractors\n",
    "            distractors = list(set(nouns) - {subject})\n",
    "\n",
    "            # Ensure there are at least three distractors\n",
    "            while len(distractors) < 3:\n",
    "                distractors.append(\"[Distractor]\")  # Placeholder for missing distractors\n",
    "\n",
    "            random.shuffle(distractors)\n",
    "            for distractor in distractors[:3]:\n",
    "                answer_choices.append(distractor)\n",
    "\n",
    "            # Shuffle the answer choices\n",
    "            random.shuffle(answer_choices)\n",
    "\n",
    "            # Append the generated MCQ to the list\n",
    "            correct_answer = chr(64 + answer_choices.index(subject) + 1)  # Convert index to letter\n",
    "            mcqs.append((question_stem, answer_choices, correct_answer))\n",
    "\n",
    "    return mcqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591c4a80-bbd5-470b-953f-712706a7e391",
   "metadata": {},
   "source": [
    "# Gradio User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9464412c-123a-410a-bbda-ac8f5773c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, tgt_lang):\n",
    "    translator = pipeline('translation', model=model, tokenizer=tokenizer, src_lang=\"eng_Latn\", tgt_lang=tgt_lang)\n",
    "    translated_text = translator(text[:1024])[0]['translation_text']\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f85ef70-876b-481d-998e-88052f33dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_video(youtube_url):\n",
    "    # Define the summarizer\n",
    "    summarizer = pipeline('summarization', max_length=56)\n",
    "    \n",
    "    # Call summarize_video function to retrieve transcript and summarize\n",
    "    summarized_text = summarize(youtube_url, summarizer)\n",
    "    \n",
    "    if summarized_text:\n",
    "        return str(summarized_text)\n",
    "    else:\n",
    "        return \"Failed to retrieve or summarize the video captions.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe8860d6-9794-497d-8e3c-c7e1c9eb3222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_mcqs(youtube_url, num_questions):\n",
    "    summarized_text = summarize_video(youtube_url)\n",
    "    mcqs = generate_mcqs(summarized_text, num_questions)\n",
    "    mcqs_with_index = [(i + 1, mcq) for i, mcq in enumerate(mcqs)]\n",
    "    formatted_mcqs = []\n",
    "    for question in mcqs_with_index:\n",
    "        formatted_question = f\"Question {question[0]}: {question[1][0]}\\nOptions:\\n\"\n",
    "        options = question[1][1]\n",
    "        for i, option in enumerate(options):\n",
    "            formatted_question += f\"{chr(97 + i)}) {option}\\n\"\n",
    "        formatted_question += f\"Correct Answer: {question[1][2]}\\n\\n\"\n",
    "        formatted_mcqs.append(formatted_question)\n",
    "    return \"\\n\".join(formatted_mcqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f23106d-d4d5-4a05-81b6-247340445fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.21.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "IMPORTANT: You are using gradio version 4.21.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks(theme='abidlabs/banana') as demo:\n",
    "    with gr.Row():\n",
    "        heading = gr.HTML(\"<h1 style='text-align:center; margin-top: 50px; margin-bottom: 20px; font-family:Bebas Neue; font-size: 40px; color:#126180;'>LANGUAGE SHUFFLE</h1>\" + \"<br>\")\n",
    "\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Translation\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    youtube_url = gr.components.Textbox(lines=1,label=\"Enter the URL:\")\n",
    "                    submit_btn = gr.components.Button(\"Submit\")\n",
    "                    output = gr.components.Textbox(lines=2, label='Captions')\n",
    "        \n",
    "                    submit_btn.click(fn=summarize_video, inputs=youtube_url, outputs=output)\n",
    "        \n",
    "                with gr.Column():\n",
    "                    tgt_lang = gr.components.Dropdown(choices=[('hindi', 'hin_Deva'), ('telugu', 'tel_Telu'), ('kanada', 'kan_Knda'), ('tamil', 'tam_Taml'), ('malayalam', 'mal_Mlym')], label='Target Language', visible=True)\n",
    "                    trans= gr.components.Textbox(lines=2, label='Translated Text')\n",
    "                   \n",
    "                    translate_btn = gr.Button('Translate')\n",
    "        \n",
    "                    translate_btn.click(translate, inputs=[output, tgt_lang], outputs=trans)\n",
    "        with gr.TabItem(\"MCQ Generator\"):\n",
    "            gr.Interface(\n",
    "                fn=url_mcqs,\n",
    "                inputs=[\n",
    "                    gr.Textbox(lines=1,label=\"Enter the URL:\"),\n",
    "                    gr.Number(minimum=3, label=\"Number of Questions\")\n",
    "                ],\n",
    "                allow_flagging=\"never\",\n",
    "                outputs=gr.Textbox(label=\"Generated MCQs\"),\n",
    "                title=\"Multiple Choice Question Generator\",\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "308f9526-92b9-46e6-986c-25d59011529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7880\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7880/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iface = demo.launch(allowed_paths=[absolute_path], share=True, inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ec748-9b9a-4a20-8d52-e5ecf082049c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
